# ======================================  训练用配置文件 ======================================


# =============================================================================================

# ===== 通用设置 ======
# 如果名字含有debug 则会有一些不同
name: base_model_train_4x_S # 实验名称 这个会作为文件夹的名字保存到experiments文件夹下
model_type: ImageRestorationModel # 在 models 文件夹下面被定义才有效
scale: 4 # 放大倍数
num_gpu: 2 # 使用的gpu数量
manual_seed: 10 # 训练种子

# ===== 原网络结构设置 （所有设置的网络都要以network_开头）=====  
network_g:
  type: NAFSSR # 在 models/arch 文件夹下面被定义才有效
  up_scale: 4 # 要和上面的scale一致

  # 下面的设置决定了网络的结构和大小
  width: 64 # 通道数
  num_blks: 32 # stereo块的个数
  drop_path_rate: 0.1
  train_size: [1, 6, 30, 90]
  drop_out_rate: 0.
  # normal_block: NAFBlock
  # fusion_block: SCAM


# ===== 数据集设置 ===== 
datasets:
  train:
    name: Flickr1024-ssr-train
    type: PairedStereoImageDatasetNew  # 这个new主要就new在 它能够读多个个文件夹的数据

    # 有多个路径 
    dataroot_gt: ~/stereo_sr/datasets/train_data/patches_x4_0/
    dataroot_lq: ~/stereo_sr/datasets/train_data/patches_x4_0/
    file_num: 2

    io_backend: # 数据保存在磁盘上
      type: disk

    # 注意这里gt的宽高是数据处理时设置lr图像的 xn 倍
    gt_size_h: 120
    gt_size_w: 360

    # 数据增强的方式
    # mean:
    # std:
    use_hflip: true
    use_vflip: true
    use_rot: false
    flip_RGB: true

    # dataloader的设置  这里主要注意 batch_size_per_gpu 太大会爆内存！
    use_shuffle: true
    num_worker_per_gpu: 8
    batch_size_per_gpu: 2
    dataset_enlarge_ratio: 1
    prefetch_mode: ~

  val: # 同上
    name: Flickr1024-ssr-val
    type: PairedStereoImageDataset
    dataroot_gt: ~/stereo_sr/datasets/val_data/hr/
    dataroot_lq: ~/stereo_sr/datasets/val_data/lr_x4/
    io_backend:
      type: disk


# ===== 路径 ===== 
path:
  pretrain_network_g: ~ # 这里不需要输入 会自动找
  strict_load_g: true
  resume_state: ~
  # 这里在解析yml文件的时候会多以下内容 
  # root: 指向user目录
  # ======== is_train==True ========
  # experiments_root ：user/experiments/name
  # log : user/experiments/name
  # training_states ：user/experiments/name/training_states
  # models ：user/experiments/name/models
  # visualization : user/experiments/name/visualization

  # ======== is_train==False ========
  # results_root : user/results/name
  # log : user/results/name
  # visualization : user/results/name/visualization



# ===== 训练设置 ===== 
train:
  optim_g:
    type: AdamW
    lr: !!float 3e-3
    weight_decay: !!float 0
    betas: [0.9, 0.9]

  scheduler:
    type: TrueCosineAnnealingLR
    T_max: 200000
    eta_min: !!float 1e-7

  total_iter: 200000
  warmup_iter: -1 # no warm up
  mixup: false

  # 训练loss的设置
  pixel_opt:
    type: MSELoss
    loss_weight: 1.
    reduction: mean


# ===== 验证设置 ===== 
val:
  val_freq: !!float 1e4 # 每n次iter验证一次 不宜太频繁，会影响训练速度
  save_img: false
  trans_num: 1

  max_minibatch: 1

  metrics: # 评价指标
    psnr: # metric name, can be arbitrary
      type: calculate_psnr
      crop_border: 0
      test_y_channel: false
    ssim:
      type: calculate_skimage_ssim


# ===== 记录和打印设置 ===== 
logger: 
  print_freq: 200 # 每n次iter打印一次
  save_checkpoint_freq: !!float 1e4 # 每n次iter保存一次模型
  use_tb_logger: true # TensorBoard 日志记录器
  wandb:
    project: ~
    resume_id: ~


# ===== 分布式训练设置 ===== 
dist_params:
  backend: nccl # 指定了分布式通信使用的后端。在PyTorch中，nccl 是专为NVIDIA GPU设计的
  port: 29500 # 用于节点间通信的端口 每个参与分布式训练的节点需要能够通过这个端口相互通信，因此这个端口应该在所有节点上保持开放
